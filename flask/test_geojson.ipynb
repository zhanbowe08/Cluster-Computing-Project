{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a dict for language proportion using sa2 code as keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from couchback_temp import CouchInterface\n",
    "import pandas as pd\n",
    "\n",
    "## Get language proportion per sa2 dataframe: e.g.\n",
    "## [{'206011105': {'Proportion': 0.29843663941024445}}, {'206011106': {'Proportion': 0.2914498871110239}}]\n",
    "\n",
    "ci = CouchInterface(address='172.26.134.62', port='5984', username='admin', password='password')\n",
    "sa2_languages = ci.non_grouped_results(db_name=\"aurin_lsahbsc_sa2\", design_doc=\"filter\", view_name=\"default\")\n",
    "\n",
    "## Build the dict\n",
    "lang_prop_dict = {}\n",
    "for output in sa2_languages:\n",
    "    # get the initial key-value pair\n",
    "    sa2 = list(output.keys())[0]\n",
    "    value = list(output.values())[0]\n",
    "    \n",
    "    if 'Proportion' in value:\n",
    "        prop = value[\"Proportion\"]\n",
    "    \n",
    "    # add to dict\n",
    "    lang_prop_dict[sa2] = prop\n",
    "\n",
    "lang_prop_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge language proportions and suburb polygons based on sa2 code\n",
    "Return a (geo)dataframe and a (geo)json string. While each dataframe row / each geojson object is a suburb (with a specific sa2 code) and includes the language proportion and the suburb polygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from couchback_temp import CouchInterface\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get language proportion per sa2 dataframe\n",
    "\n",
    "ci = CouchInterface(address='172.26.134.62', port='5984', username='admin', password='password')\n",
    "sa2_languages = ci.non_grouped_results(db_name=\"aurin_lsahbsc_sa2\", design_doc=\"filter\", view_name=\"default\")\n",
    "\n",
    "## get a list of re-structured dict / json object (each object is a suburb)\n",
    "for output in sa2_languages:\n",
    "    # get the initial key-value pair\n",
    "    sa2 = list(output.keys())[0]\n",
    "    value = list(output.values())[0]\n",
    "    \n",
    "    if 'Proportion' in value:\n",
    "        prop = value[\"Proportion\"]\n",
    "    \n",
    "    # re-construct the dict\n",
    "    output[\"sa2\"] = sa2\n",
    "    output[\"prop\"] = prop\n",
    "    del output[sa2]\n",
    "    \n",
    "sa2_languages[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert to dataframe\n",
    "languages_df = pd.DataFrame(sa2_languages)\n",
    "languages_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get polygon pf each sa2 dataframe\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "sa2_polygons = ci.non_grouped_results(db_name=\"abs_austgeo_sa2\", design_doc=\"filter\", view_name=\"default\")\n",
    "sa2_polygons[:2]\n",
    "\n",
    "## get a list of re-structured dict / json object (each object is a suburb)\n",
    "for output in sa2_polygons:\n",
    "    # get the initial key-value pair\n",
    "    sa2 = list(output.keys())[0]\n",
    "    value = list(output.values())[0]\n",
    "    \n",
    "    # re-construct the dict\n",
    "    try:\n",
    "        output[\"sa2\"] = str(sa2)\n",
    "        output[\"name\"] = value['SA2_NAME16']\n",
    "        \n",
    "        ## round coordinates (a list of lists of coords - map will apply the lambda fun to both elements)\n",
    "        rounded_polygon = [list(map(lambda x:round(x, 5), coords)) for coords in value['geometry'][0]]\n",
    "        \n",
    "        ## convert to a polygon object\n",
    "        output[\"geometry\"] = Polygon(rounded_polygon)\n",
    "        del output[sa2]\n",
    "        \n",
    "    except(TypeError):\n",
    "        # some empty geometry? can't get rounded_polygon\n",
    "        del output[sa2]\n",
    "\n",
    "## convert to dataframe\n",
    "polygons_df = pd.DataFrame(sa2_polygons)\n",
    "polygons_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge two dataframes based on sa2 code\n",
    "\n",
    "merged_df = languages_df.merge(polygons_df, on=\"sa2\")\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert to geopandas dataframe and write as a geojson file\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "polygon_gdf = gpd.GeoDataFrame(merged_df, geometry=merged_df[\"geometry\"])\n",
    "polygon_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon_gdf.to_file(\"polygon_vs_proportion.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Read a geojson file as a dict\n",
    "import json\n",
    "\n",
    "with open(\"polygon_vs_proportion.geojson\") as f:\n",
    "    geo_dict = json.load(f)\n",
    "\n",
    "geo_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 2. Read a geojson file as a geopandas dataframe\n",
    "import geopandas as gpd\n",
    "\n",
    "geo_df = gpd.read_file('polygon_vs_proportion.geojson')\n",
    "geo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert a geopandas dataframe to (geo)json (string representaion of dict)\n",
    "geo_df.to_json()\n",
    "\n",
    "## Load the string representation of json/dict back into dict\n",
    "import json\n",
    "json.loads(geo_df.to_json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Tweets with coordinates and compound sentiment score\n",
    "Return a (geo)dataframe and a (geo)json string. While each dataframe row / each geojson object is an individual tweet and includes the compound sentiment score and the point coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from couchback_temp import CouchInterface\n",
    "import pandas as pd\n",
    "\n",
    "ci = CouchInterface(address='172.26.134.62', port='5984', username='admin', password='password')\n",
    "\n",
    "## Since we want individual tweets, the view must have no reduce function, and no group.\n",
    "## If there is a reduce function and also no group, there will be a full aggregation and no key available.\n",
    "valid_tweets = ci.non_grouped_results(db_name=\"twitter_historic\", \n",
    "                                       design_doc=\"tweets\", view_name=\"election_tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from shapely.geometry import Point\n",
    "\n",
    "tweets = []\n",
    "\n",
    "## get a list of re-structured tweet dict / json object\n",
    "for tweet in valid_tweets:\n",
    "    value = list(tweet.values())[0]\n",
    "    \n",
    "    # convert tweet timestamp to python datatime\n",
    "    # e.g. 'Sun Aug 03 08:25:21 +0000 2014' to 2014-08-03 08:25:21\n",
    "    dtime = value['time']\n",
    "    new_dtime = datetime.strftime(datetime.strptime(dtime,'%a %b %d %H:%M:%S +0000 %Y'), '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    # convert to a point object\n",
    "    coord = value['coord']\n",
    "    coord = Point(coord)\n",
    "    \n",
    "    tweets.append({\"compound\":value['compound'], \"created_at\":new_dtime, \"text\":value['text'],\n",
    "                   \"geometry\":coord})\n",
    "\n",
    "## convert to dataframe\n",
    "tweets_df = pd.DataFrame(tweets); tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert to geopandas dataframe\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "tweets_gdf = gpd.GeoDataFrame(tweets_df, geometry=tweets_df[\"geometry\"])\n",
    "tweets_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to (geo)json string and then load back to dict\n",
    "json.loads(tweets_gdf.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54] 5.633333333333329\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([5, 15, 25, 35, 45, 55]).reshape((-1, 1))\n",
    "y = np.array([5, 20, 14, 32, 22, 38])\n",
    "\n",
    "reg = LinearRegression().fit(x, y)\n",
    "print(reg.coef_, reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  26.,   76.,  126.,  176.,  226.,  276.],\n",
       "       [  76.,  226.,  376.,  526.,  676.,  826.],\n",
       "       [ 126.,  376.,  626.,  876., 1126., 1376.],\n",
       "       [ 176.,  526.,  876., 1226., 1576., 1926.],\n",
       "       [ 226.,  676., 1126., 1576., 2026., 2476.],\n",
       "       [ 276.,  826., 1376., 1926., 2476., 3026.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "a = np.array([5, 15, 25, 35, 45, 55])\n",
    "i = np.ones(a.shape)\n",
    "X = np.vstack((i, a))\n",
    "\n",
    "X = np.transpose(X)\n",
    "\n",
    "y = np.array([6,10, 22,30, 38, 51])\n",
    "\n",
    "X.dot(X.T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
